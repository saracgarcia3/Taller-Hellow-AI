{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a1b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Cliente OpenAI inicializado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5245b6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Hola, universo digital! üååü§ñ Soy tu asistente virtual, aqu√≠ para iluminar tu curiosidad y explorar juntos las infinitas posibilidades del conocimiento. ¬øListo para emprender esta aventura? ¬°Comencemos! üöÄ‚ú®\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Escribe un saludo tipo 'Hello World' con un toque creativo de IA.\"\n",
    "resp = client.chat.completions.create(\n",
    " model=\"gpt-4o-mini\",\n",
    " messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    " temperature=0.6\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f559a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- temperature=0.1 ---\n",
      "La inteligencia artificial (IA) es un campo de la inform√°tica que se centra en la creaci√≥n de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como el aprendizaje, el razonamiento, la comprensi√≥n del lenguaje natural, la\n",
      "\n",
      "--- temperature=0.5 ---\n",
      "La inteligencia artificial (IA) es una rama de la inform√°tica que se centra en la creaci√≥n de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como el aprendizaje, el razonamiento, la percepci√≥n, la comprensi√≥n del lenguaje\n",
      "\n",
      "--- temperature=0.9 ---\n",
      "La inteligencia artificial (IA) es un √°rea de la inform√°tica que se centra en la creaci√≥n de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como el aprendizaje, el razonamiento, la percepci√≥n y la comprensi√≥n del lenguaje\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [0.1, 0.5, 0.9]:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Describe brevemente qu√© es la IA.\"}\n",
    "        ],\n",
    "        temperature=t,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    print(f\"--- temperature={t} ---\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9954ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb134d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado. Modelo listo para consultas.\n"
     ]
    }
   ],
   "source": [
    "# 3) Cargar la clave y crear el cliente\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # Lee el archivo .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Cliente inicializado. Modelo listo para consultas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c3c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La inteligencia artificial en la educaci√≥n se refiere al uso de tecnolog√≠as avanzadas para personalizar el aprendizaje, adaptando los contenidos y m√©todos a las necesidades individuales de cada estudiante. Adem√°s, facilita la automatizaci√≥n de tareas administrativas y el an√°lisis de datos para mejorar la toma de decisiones educativas y el rendimiento acad√©mico.\n"
     ]
    }
   ],
   "source": [
    "# 5) Primera consulta: respuesta libre\n",
    "prompt = \"Explica en dos frases qu√© es la inteligencia artificial en la educaci√≥n.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7  # m√°s creativo que 0.2, menos que 1.0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ed5783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"operation\": \"explanation\",\n",
      "  \"input\": \"¬øQu√© es aprendizaje supervisado?\",\n",
      "  \"output\": \"El aprendizaje supervisado es un tipo de aprendizaje autom√°tico donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada en el conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir la salida para nuevas entradas bas√°ndose en patrones encontrados en los datos de entrenamiento.\"\n",
      "}\n",
      "\n",
      "Valid JSON ‚Üí {'operation': 'explanation', 'input': '¬øQu√© es aprendizaje supervisado?', 'output': 'El aprendizaje supervisado es un tipo de aprendizaje autom√°tico donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada en el conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir la salida para nuevas entradas bas√°ndose en patrones encontrados en los datos de entrenamiento.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "query = \"¬øQu√© es aprendizaje supervisado?\"\n",
    "schema_instruction = (\n",
    "    \"Responde en formato JSON con las claves: operation, input, output. \"\n",
    "    \"operation debe ser 'explanation'; input debe repetir la pregunta; output la explicaci√≥n clara y breve.\"\n",
    ")\n",
    "response_json = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": schema_instruction},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ],\n",
    "    temperature=0.3,       # m√°s determinista para formatos estructurados\n",
    "    max_tokens=300         # suficiente para una explicaci√≥n breve\n",
    ")\n",
    "text = response_json.choices[0].message.content\n",
    "print(text)\n",
    "\n",
    "# (Opcional) intentar cargar como JSON si el modelo devolvi√≥ un objeto v√°lido\n",
    "try:\n",
    "    data = json.loads(text)\n",
    "    print(\"\\nValid JSON ‚Üí\", data)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\nLa salida no es JSON v√°lido literal. Puedes parsearla manualmente o usar validadores/funciones JSON del proveedor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e50aed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid value: 'text'. Supported values are: 'input_text', 'input_image', 'output_text', 'refusal', 'input_file', 'computer_screenshot', and 'summary_text'.\", 'type': 'invalid_request_error', 'param': 'input[0].content[0].type', 'code': 'invalid_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0.1\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.9\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDescribe brevemente qu√© es la IA.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m  \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- temperature=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(resp.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:840\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    804\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    805\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    838\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    839\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid value: 'text'. Supported values are: 'input_text', 'input_image', 'output_text', 'refusal', 'input_file', 'computer_screenshot', and 'summary_text'.\", 'type': 'invalid_request_error', 'param': 'input[0].content[0].type', 'code': 'invalid_value'}}"
     ]
    }
   ],
   "source": [
    "for t in [0.1, 0.5, 0.9]:\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe brevemente qu√© es la IA.\"}\n",
    "            ]\n",
    "        }],\n",
    "        temperature=t,\n",
    "        max_output_tokens=50  \n",
    "    )\n",
    "    print(f\"--- temperature={t} ---\")\n",
    "    print(resp.output_text)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501f5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- temperature=0.1 ---\n",
      "La inteligencia artificial (IA) es una rama de la inform√°tica que se centra en crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como el aprendizaje, el razonamiento, la comprensi√≥n del lenguaje natural, la percepci√≥n visual y la\n",
      "\n",
      "--- temperature=0.5 ---\n",
      "La inteligencia artificial (IA) es un campo de la inform√°tica que se centra en la creaci√≥n de sistemas capaces de realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como el aprendizaje, el razonamiento, la percepci√≥n y la toma de decisiones. La\n",
      "\n",
      "--- temperature=0.9 ---\n",
      "La inteligencia artificial (IA) es un campo de la inform√°tica que se centra en crear sistemas capaces de realizar tareas que, normalmente, requieren inteligencia humana. Esto incluye habilidades como el reconocimiento de voz, el aprendizaje, la toma de decisiones y la resoluci√≥n de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [0.1, 0.5, 0.9]:\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=\"Describe brevemente qu√© es la IA.\",\n",
    "        temperature=t,\n",
    "        max_output_tokens=50\n",
    "    )\n",
    "    print(f\"--- temperature={t} ---\")\n",
    "    try:\n",
    "        print(resp.output_text)\n",
    "    except AttributeError:\n",
    "        print(resp.output[0].content[0].text)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e223c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.15.0)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.10.23-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/878.7 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------- --- 786.4/878.7 kB 882.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 878.7/878.7 kB 857.5 kB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Downloading regex-2025.10.23-cp312-cp312-win_amd64.whl (276 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp312-cp312-win_amd64.whl (112 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, tenacity, regex, ormsgpack, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "Successfully installed jsonpatch-1.33 langchain-1.0.2 langchain-core-1.0.1 langchain-openai-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 regex-2025.10.23 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee162e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontr√≥ la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe21c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje autom√°tico es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar su rendimiento en tareas espec√≠ficas a partir de datos sin ser programadas expl√≠citamente para ello. Utiliza algoritmos para identificar patrones y hacer predicciones o decisiones basadas en la informaci√≥n proporcionada.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje autom√°tico\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec465ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleSequentialChain\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Primer paso: obtener una descripci√≥n\u001b[39;00m\n\u001b[32m      4\u001b[39m primer_prompt = PromptTemplate(\n\u001b[32m      5\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mtema\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33mExplica brevemente el concepto de \u001b[39m\u001b[38;5;132;01m{tema}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Primer paso: obtener una descripci√≥n\n",
    "primer_prompt = PromptTemplate(\n",
    "    input_variables=[\"tema\"],\n",
    "    template=\"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_chain = LLMChain(llm=llm, prompt=primer_prompt)\n",
    "\n",
    "# Segundo paso: generar aplicaci√≥n educativa\n",
    "segundo_prompt = PromptTemplate(\n",
    "    input_variables=[\"concepto\"],\n",
    "    template=\"Prop√≥n una aplicaci√≥n educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_chain = LLMChain(llm=llm, prompt=segundo_prompt)\n",
    "\n",
    "# Combinar ambos pasos en una cadena secuencial\n",
    "chain_secuencial = SimpleSequentialChain(chains=[primer_chain, segundo_chain])\n",
    "\n",
    "# Ejecutar la cadena completa\n",
    "resultado = chain_secuencial.run(\"realidad aumentada\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbb4304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicaci√≥n Educativa: \"Exploradores del Conocimiento\"**\n",
      "\n",
      "**Descripci√≥n General:**\n",
      "\"Exploradores del Conocimiento\" es una aplicaci√≥n educativa de realidad aumentada (RA) dise√±ada para estudiantes de educaci√≥n primaria y secundaria. Su objetivo es enriquecer el aprendizaje de diversas materias, como ciencias, historia y geograf√≠a, al superponer contenido digital interactivo sobre el entorno real de los estudiantes, facilitando la comprensi√≥n y el inter√©s por los temas tratados.\n",
      "\n",
      "**Caracter√≠sticas de la Aplicaci√≥n:**\n",
      "\n",
      "1. **Exploraci√≥n de Entornos Reales:**\n",
      "   - Los estudiantes pueden apuntar sus dispositivos m√≥viles hacia objetos o lugares espec√≠ficos en su entorno (como plantas, monumentos, mapas, etc.) para recibir informaci√≥n adicional en forma de im√°genes, videos o textos explicativos.\n",
      "   - Por ejemplo, al apuntar hacia una planta, la aplicaci√≥n puede mostrar datos sobre su clasificaci√≥n, h√°bitat y caracter√≠sticas.\n",
      "\n",
      "2. **Actividades Interactivas:**\n",
      "   - La aplicaci√≥n incluye actividades interactivas que permiten a los estudiantes realizar experimentos virtuales o simulaciones. Por ejemplo, en una clase de ciencias, pueden observar c√≥mo se lleva a cabo la fotos√≠ntesis al apuntar a una planta, viendo una animaci√≥n que explica el proceso.\n",
      "   - En historia, los estudiantes pueden \"ver\" c√≥mo era un lugar en el pasado al apuntar su dispositivo hacia un sitio hist√≥rico, mostrando reconstrucciones 3D de eventos o edificaciones.\n",
      "\n",
      "3. **Juego de Preguntas y Respuestas:**\n",
      "   - La aplicaci√≥n ofrece un modo de juego donde los estudiantes pueden participar en un quiz interactivo. Al escanear ciertos objetos o lugares, se les presentan preguntas relacionadas, y pueden ganar puntos por respuestas correctas, fomentando la competencia y el aprendizaje l√∫dico.\n",
      "\n",
      "4. **Realidad Aumentada Colaborativa:**\n",
      "   - Los estudiantes pueden trabajar en grupos, utilizando la RA para colaborar en proyectos. Por ejemplo, pueden crear presentaciones en grupo donde cada miembro a√±ade informaci√≥n digital sobre un tema espec√≠fico, que luego se superpone en un espacio f√≠sico compartido.\n",
      "\n",
      "5. **Seguimiento del Progreso:**\n",
      "   - La aplicaci√≥n incluye un sistema de seguimiento que permite a los profesores monitorear el progreso de los estudiantes, ver qu√© temas han dominado y en cu√°les necesitan m√°s ayuda, facilitando una ense√±anza personalizada.\n",
      "\n",
      "6. **Integraci√≥n con el Curr√≠culo:**\n",
      "   - \"Exploradores del Conocimiento\" se alinea con los planes de estudio de diversas materias, proporcionando recursos y actividades que complementan lo que se ense√±a en clase.\n",
      "\n",
      "**Beneficios de la Aplicaci√≥n:**\n",
      "- Aumenta la motivaci√≥n y el inter√©s de los estudiantes al hacer que el aprendizaje sea m√°s interactivo y atractivo.\n",
      "- Facilita la comprensi√≥n de conceptos complejos al permitir la visualizaci√≥n de informaci√≥n en un contexto real.\n",
      "- Fomenta el trabajo en equipo y la colaboraci√≥n entre estudiantes.\n",
      "- Promueve el aprendizaje activo, donde los estudiantes son participantes activos en su proceso educativo.\n",
      "\n",
      "Con \"Exploradores del Conocimiento\", la realidad aumentada se convierte en una herramienta poderosa para transformar la educaci√≥n, haciendo que el aprendizaje sea m√°s accesible, din√°mico y divertido.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicaci√≥n educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Prop√≥n una aplicaci√≥n educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff4e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Hola! ¬øEn qu√© puedo ayudarte hoy con respecto a la ense√±anza de inform√°tica?\n",
      "Claro, aqu√≠ tienes algunas ideas para introducir la inteligencia artificial (IA) a tus estudiantes:\n",
      "\n",
      "1. **Conceptos B√°sicos**: Comienza explicando qu√© es la IA, sus aplicaciones y su importancia en la vida cotidiana. Utiliza ejemplos como asistentes virtuales (Siri, Alexa) o recomendaciones de pel√≠culas (Netflix).\n",
      "\n",
      "2. **Historia de la IA**: Ofrece una breve historia sobre el desarrollo de la IA, desde sus inicios hasta los avances recientes. Esto ayudar√° a los estudiantes a entender su evoluci√≥n y contexto.\n",
      "\n",
      "3. **Tipos de IA**: Explica las diferencias entre IA d√©bil (narrow AI) y IA fuerte (general AI), as√≠ como los conceptos de aprendizaje autom√°tico (machine learning) y aprendizaje profundo (deep learning).\n",
      "\n",
      "4. **Herramientas y Lenguajes**: Introduce herramientas y lenguajes de programaci√≥n utilizados en IA, como Python, TensorFlow y scikit-learn. Puedes mostrar ejemplos simples de c√≥digo.\n",
      "\n",
      "5. **Proyectos Pr√°cticos**: Dise√±a proyectos donde los estudiantes puedan aplicar IA. Por ejemplo, crear un chatbot b√°sico, un sistema de recomendaci√≥n o un clasificador de im√°genes.\n",
      "\n",
      "6. **√âtica en IA**: Discute las implicaciones √©ticas de la IA, como la privacidad, el sesgo algor√≠tmico y el impacto en el empleo. Esto fomentar√° el pensamiento cr√≠tico.\n",
      "\n",
      "7. **Recursos Adicionales**: Proporciona recursos como cursos en l√≠nea, libros y videos que los estudiantes pueden explorar para profundizar en el tema.\n",
      "\n",
      "8. **Invitados Especiales**: Considera invitar a expertos en IA para que hablen sobre su trabajo y experiencias en el campo.\n",
      "\n",
      "Recuerda adaptar el contenido al nivel de tus estudiantes y fomentar la participaci√≥n activa. ¬°Buena suerte!\n",
      "Aqu√≠ tienes algunos ejemplos pr√°cticos que puedes utilizar en clase para ense√±ar sobre inteligencia artificial:\n",
      "\n",
      "1. **Chatbots**:\n",
      "   - **Actividad**: Pide a los estudiantes que creen un chatbot simple utilizando plataformas como Dialogflow o Chatbot.com.\n",
      "   - **Objetivo**: Aprender sobre procesamiento de lenguaje natural y c√≥mo se comunican los chatbots con los usuarios.\n",
      "\n",
      "2. **Clasificaci√≥n de Im√°genes**:\n",
      "   - **Actividad**: Usa herramientas como Teachable Machine de Google para que los estudiantes creen un modelo que clasifique im√°genes (por ejemplo, entre gatos y perros).\n",
      "   - **Objetivo**: Introducir conceptos de aprendizaje autom√°tico y redes neuronales.\n",
      "\n",
      "3. **Recomendaciones de Pel√≠culas**:\n",
      "   - **Actividad**: Muestra c√≥mo funcionan los sistemas de recomendaci√≥n utilizando un conjunto de datos simple. Los estudiantes pueden implementar un sistema b√°sico en Python.\n",
      "   - **Objetivo**: Entender c√≥mo se utilizan los algoritmos para hacer recomendaciones personalizadas.\n",
      "\n",
      "4. **An√°lisis de Sentimientos**:\n",
      "   - **Actividad**: Utiliza una API de an√°lisis de sentimientos (como la de TextBlob o VADER) para analizar comentarios de redes sociales o rese√±as de productos.\n",
      "   - **Objetivo**: Aprender sobre el procesamiento de texto y c√≥mo la IA puede interpretar emociones.\n",
      "\n",
      "5. **Reconocimiento de Voz**:\n",
      "   - **Actividad**: Usa herramientas como Google Speech-to-Text API para que los estudiantes conviertan voz en texto.\n",
      "   - **Objetivo**: Introducir conceptos de reconocimiento de voz y su aplicaci√≥n en asistentes virtuales.\n",
      "\n",
      "6. **Juegos con IA**:\n",
      "   - **Actividad**: Crea un juego simple donde los estudiantes programen una IA para jugar contra ellos (por ejemplo, un juego de tres en raya).\n",
      "   - **Objetivo**: Aprender sobre algoritmos de toma de decisiones y estrategias en juegos.\n",
      "\n",
      "7. **Proyectos de Datasets Abiertos**:\n",
      "   - **Actividad**: Proporciona a los estudiantes acceso a datasets abiertos (como Kaggle) y p√≠deles que realicen un an√°lisis o predicci√≥n.\n",
      "   - **Objetivo**: Fomentar el an√°lisis de datos y la aplicaci√≥n de modelos de IA en problemas del mundo real.\n",
      "\n",
      "8. **Simulaciones de IA**:\n",
      "   - **Actividad**: Utiliza plataformas como AI Dungeon, donde los estudiantes pueden interactuar con una IA en un entorno narrativo.\n",
      "   - **Objetivo**: Ver c√≥mo la IA puede generar texto y c√≥mo se puede utilizar en la creaci√≥n de historias.\n",
      "\n",
      "Estos ejemplos no solo hacen que la clase sea m√°s interesante, sino que tambi√©n permiten a los estudiantes aplicar lo que han aprendido de manera pr√°ctica. ¬°Espero que encuentres √∫tiles estas ideas!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ‚Üê aqu√≠ va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Env√≠a un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de inform√°tica.\"))\n",
    "print(chat(\"¬øPuedes explicarme c√≥mo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¬øQu√© ejemplos pr√°cticos puedo usar en la clase?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello_ai_vscode",
   "language": "python",
   "name": "hello_ai_vscode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
